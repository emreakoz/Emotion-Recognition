# Emotion-Recognition
This repository builds a neural network to detect emotions such as anger, disgust, fear, happiness, sadness, surprise, neutral and comfort from facial expressions. 

The initial part of the training was done with a deep CNN on the University of Denver's AffectNet database (420K labeled facial expressions). To fine tune the network, 600 marathon runner facial expressisons were labeled manually by looking at five years of Chicago and London Marathon runner pictures from 2014 to 2018. Furthermore, certain demographics such as age, gender, pace etc. were scraped from Chicago and London Marathons to be used for predictions together with the images.

The CNN was trained with 420K labeled facial expressions and weights were saved. Then, a parallel multilayer perceptron was trained with the demographics information and merged with the CNN to take into account both the facial expressions and the correlations coming from the demographics in predictions. This bilinear network was trained with the actual marathon images and demographics while keeping the majority of the CNN's weights frozen. In other words, I fine tuned the CNN while training the artificial neural network.

Feel free to use the weights of the vision network. The best test set performance is achieved with this one: image_models/weights/model_weights_v7.h5. The network should be able to capture your emotions almost as good as a commercial software as long as you just give a face image to it. Finally, documentation of the project is in image_models/capstone_project.ipynb and a web app of the project can be found here: https://nostradamusproject.herokuapp.com/
